{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input -> NN.module.forward() -> output, 网络内: 卷积 -> 非线性 -> 卷积 -> 非线性 -> 输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch的nn.Module是所有神经网络模块的基类。你可以通过继承这个类来创建自己的神经网络模型：\n",
    "\n",
    "- 定义模型：通过继承nn.Module类并在__init__方法中定义网络层\n",
    "- 前向传播：在forward方法中定义数据的前向传播过程\n",
    "- 模块嵌套：nn.Module允许模块嵌套，可以将子模块作为属性添加到父模块中，从而构建复杂的网络结构\n",
    "- 参数管理：所有定义在nn.Module中的参数都会自动注册，并且可以通过parameters()方法访问\n",
    "- 训练和评估模式：通过model.train()和model.eval()方法切换模型的训练和评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN模板\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyNN(nn.Module):  # 必须继承自nn.Module\n",
    "    def __init__(self):\n",
    "        super(MyNN,self).__init__()\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = input + 1\n",
    "        return output\n",
    "\n",
    "mynn = MyNN()\n",
    "x = torch.tensor(1.0)\n",
    "output = mynn(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch的卷积层（Convolution Layers）是构建卷积神经网络（CNN）的基础：\n",
    "\n",
    "- Conv2d: 这是最常用的2D卷积层，用于处理图像数据。它的主要参数包括：\n",
    "    - in_channels: 输入特征的通道数，例如灰度图像有1个通道，彩色图像有3个通道\n",
    "    - out_channels: 卷积核的数量，即输出特征的通道数。\n",
    "    - kernel_size: 卷积核的大小，可以是单个整数或一个整数元组。\n",
    "    - stride: 卷积操作的步幅，控制卷积核移动的步长。\n",
    "    - padding: 输入图像的填充方式，可以是整数或字符串（如’valid’或’same’）\n",
    "    - dilation: 卷积核元素之间的间距\n",
    "- Conv3d: 用于3D数据的卷积层，适用于视频或3D图像处理\n",
    "- ConvTranspose2d: 反卷积层（或转置卷积层），常用于生成对抗网络（GAN）中的上采样操作。\n",
    "- Groups: 控制输入和输出之间的连接方式。例如，groups=1表示所有输入通道与所有输出通道相连，而groups=in_channels表示每个输入通道与其自己的卷积核相连\n",
    "\n",
    "tips: 卷积核可以理解为ouput之于input的投影(详见PyTorch官方文档-Convolution arithmetic)\n",
    "\n",
    "这些卷积层可以通过torch.nn模块轻松定义和使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "dataset = torchvision.datasets.CIFAR10(root=r\"..\\data\\test\",train=False,transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "daraloader = DataLoader(dataset=dataset,batch_size=64,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyCNN,self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3,out_channels=6,kernel_size=(3,3),stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "    \n",
    "mycnn = MyCNN()\n",
    "print(mycnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"logs\")\n",
    "step = 0\n",
    "for data in daraloader:\n",
    "    imgs,targets = data\n",
    "    output = mycnn(imgs)\n",
    "    # torch.Size([64,3,30,30])\n",
    "    writer.add_images(tag=\"input\",img_tensor=imgs,global_step=step)\n",
    "    # torch.Size([64,6,30,30]),Tensorboard不好显示\n",
    "    output = torch.reshape(input=output,shape=(-1,3,30,30))  # -> torch.Size([xxx,3,30,30])\n",
    "    writer.add_images(tag=\"output\",img_tensor=output,global_step=step)\n",
    "    step += 1\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
