{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 提供了多种损失函数，用于不同的任务和模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用损失函数:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 Loss (绝对值误差损失): 计算输出和目标之间差值的绝对值。适用于回归任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loss = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE Loss (均方误差损失): 计算输出和目标之间差值的平方。也常用于回归任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy Loss (交叉熵损失): 常用于分类任务，特别是多分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 PyTorch 中，反向传播（Backpropagation）是通过自动微分来实现的：\n",
    "\n",
    "- 前向传播: 计算模型的输出\n",
    "- 计算损失: 使用损失函数计算模型输出与真实值之间的差异\n",
    "- 反向传播: 通过调用 loss.backward() 计算损失函数对每个模型参数的梯度\n",
    "- 更新参数: 使用优化器（如 torch.optim.SGD）根据计算出的梯度更新模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义一个简单的线性模型\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # lr: learning rate,太大不稳定,太小速度慢\n",
    "\n",
    "# 输入和目标数据\n",
    "inputs = torch.tensor([[1.0], [2.0], [3.0]], requires_grad=True)\n",
    "targets = torch.tensor([[2.0], [4.0], [6.0]])\n",
    "\n",
    "# 前向传播\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, targets)\n",
    "\n",
    "# 反向传播\n",
    "loss.backward()\n",
    "\n",
    "# 更新参数\n",
    "optimizer.step()\n",
    "\n",
    "# 再次优化时优化器要清零,否则梯度爆炸影响结果\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "print(f'Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 前向传播: 计算模型的输出 outputs = model(inputs)\n",
    "- 计算损失: 使用均方误差损失函数 loss = criterion(outputs, targets)\n",
    "- 反向传播: 调用 loss.backward() 计算梯度\n",
    "- 更新参数: 调用 optimizer.step() 更新模型参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
